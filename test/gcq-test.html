<!DOCTYPE html>
<html>
<head>
  <title>GCQ Runtime Test</title>
  <style>
    body { font-family: system-ui; padding: 20px; max-width: 800px; margin: 0 auto; }
    pre { background: #f5f5f5; padding: 10px; overflow-x: auto; }
    .success { color: green; }
    .error { color: red; }
    .info { color: blue; }
    button { padding: 10px 20px; font-size: 16px; cursor: pointer; }
    #log { white-space: pre-wrap; font-family: monospace; }
  </style>
</head>
<body>
  <h1>GCQ Runtime Test</h1>

  <div>
    <p>Model URL: <input type="text" id="modelUrl" value="http://localhost:8888/translategemma-gcq-fine.gcq" style="width: 400px;"></p>
    <button onclick="runTest()">Run Test</button>
    <button onclick="checkWebGPU()">Check WebGPU</button>
  </div>

  <h2>Log</h2>
  <div id="log"></div>

  <script type="module">
    // GCQ Runtime - inline for testing
    const GCQ_MAGIC = 0x34514347;

    function log(msg, type = 'info') {
      const el = document.getElementById('log');
      const span = document.createElement('span');
      span.className = type;
      span.textContent = msg + '\n';
      el.appendChild(span);
      console.log(msg);
    }

    function fp16ToF32(h) {
      const sign = (h >> 15) & 0x1;
      const exp = (h >> 10) & 0x1f;
      const frac = h & 0x3ff;
      if (exp === 0) {
        if (frac === 0) return sign ? -0 : 0;
        return (sign ? -1 : 1) * Math.pow(2, -14) * (frac / 1024);
      }
      if (exp === 31) {
        return frac === 0 ? (sign ? -Infinity : Infinity) : NaN;
      }
      return (sign ? -1 : 1) * Math.pow(2, exp - 15) * (1 + frac / 1024);
    }

    window.checkWebGPU = async function() {
      document.getElementById('log').innerHTML = '';

      if (!navigator.gpu) {
        log('WebGPU NOT supported in this browser', 'error');
        return;
      }
      log('WebGPU API available', 'success');

      try {
        const adapter = await navigator.gpu.requestAdapter({ powerPreference: 'high-performance' });
        if (!adapter) {
          log('No WebGPU adapter found', 'error');
          return;
        }
        log('WebGPU adapter: ' + adapter.name, 'success');

        const device = await adapter.requestDevice({
          requiredLimits: {
            maxStorageBufferBindingSize: 1024 * 1024 * 1024,
            maxBufferSize: 1024 * 1024 * 1024,
          }
        });
        log('WebGPU device created', 'success');
        log('Max buffer size: ' + (device.limits.maxBufferSize / 1e9).toFixed(2) + ' GB', 'info');
        log('Max storage buffer: ' + (device.limits.maxStorageBufferBindingSize / 1e9).toFixed(2) + ' GB', 'info');

      } catch (e) {
        log('WebGPU error: ' + e.message, 'error');
      }
    };

    window.runTest = async function() {
      document.getElementById('log').innerHTML = '';
      const modelUrl = document.getElementById('modelUrl').value;

      log('Testing GCQ Runtime', 'info');
      log('Model: ' + modelUrl, 'info');
      log('', 'info');

      // Check WebGPU
      if (!navigator.gpu) {
        log('WebGPU not supported', 'error');
        return;
      }
      log('WebGPU: OK', 'success');

      // Initialize device
      const adapter = await navigator.gpu.requestAdapter({ powerPreference: 'high-performance' });
      const device = await adapter.requestDevice({
        requiredLimits: {
          maxStorageBufferBindingSize: 1024 * 1024 * 1024,
          maxBufferSize: 1024 * 1024 * 1024,
        }
      });
      log('Device: OK', 'success');

      // Fetch model
      log('Fetching model...', 'info');
      let buffer;
      try {
        const response = await fetch(modelUrl);
        if (!response.ok) throw new Error('HTTP ' + response.status);
        buffer = await response.arrayBuffer();
        log('Downloaded: ' + (buffer.byteLength / 1e9).toFixed(2) + ' GB', 'success');
      } catch (e) {
        log('Fetch error: ' + e.message, 'error');
        log('TIP: Run "python3 -m http.server 8000" in the models directory', 'info');
        return;
      }

      // Parse header
      const view = new DataView(buffer);
      const magic = view.getUint32(0, true);

      if (magic !== GCQ_MAGIC) {
        log('Invalid magic: 0x' + magic.toString(16) + ' (expected GCQ4)', 'error');
        return;
      }
      log('Magic: GCQ4', 'success');

      const version = view.getUint32(4, true);
      log('Version: ' + version, 'success');

      const manifestOffset = Number(view.getBigUint64(8, true));
      const manifestSize = Number(view.getBigUint64(16, true));

      // Parse manifest
      const manifestBytes = new Uint8Array(buffer, manifestOffset, manifestSize);
      const manifest = JSON.parse(new TextDecoder().decode(manifestBytes));

      log('Format: ' + manifest.format, 'success');
      log('Bits: ' + manifest.bits, 'success');
      log('Block size: ' + manifest.block_size, 'success');
      log('Components: ' + manifest.components.length, 'success');

      // Parse codebook
      const nCentroids = manifest.n_centroids || 16;
      const codebookU16 = new Uint16Array(buffer, manifest.codebook_offset, nCentroids);
      const codebook = [];
      for (let i = 0; i < nCentroids; i++) {
        codebook.push(fp16ToF32(codebookU16[i]).toFixed(3));
      }
      log('Codebook: [' + codebook.slice(0, 4).join(', ') + ', ..., ' + codebook.slice(-2).join(', ') + ']', 'success');

      // List components
      log('', 'info');
      log('Components:', 'info');
      for (const comp of manifest.components) {
        log('  ' + comp.name + ': ' + comp.tensors.length + ' tensors, ' + (comp.size / 1e6).toFixed(1) + ' MB', 'info');
      }

      // Test dequantization on a small tensor
      log('', 'info');
      log('Testing dequantization...', 'info');

      const testTensor = manifest.components[0].tensors.find(t => t.original_size > 1000 && t.original_size < 100000);
      if (testTensor) {
        log('Test tensor: ' + testTensor.name, 'info');
        log('  Shape: [' + testTensor.original_shape.join(', ') + ']', 'info');
        log('  Size: ' + testTensor.original_size + ' elements', 'info');

        // Create WebGPU shader and test
        const shaderCode = `
          struct Params {
            num_elements: u32,
            block_size: u32,
          }
          @group(0) @binding(0) var<uniform> params: Params;
          @group(0) @binding(1) var<storage, read> indices: array<u32>;
          @group(0) @binding(2) var<storage, read> scales: array<f32>;
          @group(0) @binding(3) var<storage, read> codebook: array<f32, 16>;
          @group(0) @binding(4) var<storage, read_write> output: array<f32>;

          @compute @workgroup_size(256)
          fn main(@builtin(global_invocation_id) id: vec3<u32>) {
            let idx = id.x;
            if (idx >= params.num_elements) { return; }
            let block_idx = idx / params.block_size;
            let scale = scales[block_idx];
            let packed_idx = idx / 8u;
            let shift = (idx % 8u) * 4u;
            let centroid_idx = (indices[packed_idx] >> shift) & 0xFu;
            output[idx] = codebook[centroid_idx] * scale;
          }
        `;

        try {
          const module = device.createShaderModule({ code: shaderCode });
          const pipeline = device.createComputePipeline({
            layout: 'auto',
            compute: { module, entryPoint: 'main' }
          });
          log('Shader compiled: OK', 'success');

          // Load tensor data
          const indicesData = new Uint8Array(buffer, testTensor.indices_offset, testTensor.indices_size);
          const scalesU16 = new Uint16Array(buffer, testTensor.scales_offset, testTensor.scales_size / 2);
          const scalesF32 = new Float32Array(scalesU16.length);
          for (let i = 0; i < scalesU16.length; i++) {
            scalesF32[i] = fp16ToF32(scalesU16[i]);
          }

          // Create buffers
          const paramsBuffer = device.createBuffer({ size: 8, usage: GPUBufferUsage.UNIFORM | GPUBufferUsage.COPY_DST });
          device.queue.writeBuffer(paramsBuffer, 0, new Uint32Array([testTensor.original_size, testTensor.block_size || manifest.block_size]));

          const indicesBuffer = device.createBuffer({ size: Math.ceil(indicesData.byteLength / 4) * 4, usage: GPUBufferUsage.STORAGE | GPUBufferUsage.COPY_DST });
          device.queue.writeBuffer(indicesBuffer, 0, indicesData);

          const scalesBuffer = device.createBuffer({ size: scalesF32.byteLength, usage: GPUBufferUsage.STORAGE | GPUBufferUsage.COPY_DST });
          device.queue.writeBuffer(scalesBuffer, 0, scalesF32);

          const codebookF32 = new Float32Array(16);
          for (let i = 0; i < nCentroids; i++) {
            codebookF32[i] = fp16ToF32(codebookU16[i]);
          }
          const codebookBuffer = device.createBuffer({ size: 64, usage: GPUBufferUsage.STORAGE | GPUBufferUsage.COPY_DST });
          device.queue.writeBuffer(codebookBuffer, 0, codebookF32);

          const outputBuffer = device.createBuffer({ size: testTensor.original_size * 4, usage: GPUBufferUsage.STORAGE | GPUBufferUsage.COPY_SRC });

          const bindGroup = device.createBindGroup({
            layout: pipeline.getBindGroupLayout(0),
            entries: [
              { binding: 0, resource: { buffer: paramsBuffer } },
              { binding: 1, resource: { buffer: indicesBuffer } },
              { binding: 2, resource: { buffer: scalesBuffer } },
              { binding: 3, resource: { buffer: codebookBuffer } },
              { binding: 4, resource: { buffer: outputBuffer } },
            ]
          });

          // Run compute shader
          const commandEncoder = device.createCommandEncoder();
          const passEncoder = commandEncoder.beginComputePass();
          passEncoder.setPipeline(pipeline);
          passEncoder.setBindGroup(0, bindGroup);
          passEncoder.dispatchWorkgroups(Math.ceil(testTensor.original_size / 256));
          passEncoder.end();

          // Read back
          const readBuffer = device.createBuffer({ size: testTensor.original_size * 4, usage: GPUBufferUsage.MAP_READ | GPUBufferUsage.COPY_DST });
          commandEncoder.copyBufferToBuffer(outputBuffer, 0, readBuffer, 0, testTensor.original_size * 4);
          device.queue.submit([commandEncoder.finish()]);

          await readBuffer.mapAsync(GPUMapMode.READ);
          const result = new Float32Array(readBuffer.getMappedRange().slice(0));
          readBuffer.unmap();

          // Show sample
          const sample = Array.from(result.slice(0, 5)).map(v => v.toFixed(4));
          log('Dequantized sample: [' + sample.join(', ') + ', ...]', 'success');

          // Stats
          const min = Math.min(...result);
          const max = Math.max(...result);
          const mean = result.reduce((a, b) => a + b, 0) / result.length;
          log('Stats: min=' + min.toFixed(4) + ', max=' + max.toFixed(4) + ', mean=' + mean.toFixed(4), 'success');

          log('', 'info');
          log('=== ALL TESTS PASSED ===', 'success');

        } catch (e) {
          log('Dequant error: ' + e.message, 'error');
          console.error(e);
        }
      } else {
        log('No suitable test tensor found', 'error');
      }
    };
  </script>
</body>
</html>
